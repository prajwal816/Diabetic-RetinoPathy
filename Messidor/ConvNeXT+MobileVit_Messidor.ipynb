{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2819730,"sourceType":"datasetVersion","datasetId":1723812}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# hybrid_supcon_234_balanced_viz_messidor_convnext_mobilevit.py\n\"\"\"\nSupCon pretrain on classes [2,3,4] with balanced batches + weighted SupCon loss,\nthen fine-tune whole hybrid model on all 5 classes with MixUp + Focal Loss,\ngradual unfreeze and multi-GPU DataParallel for the classifier stage.\n\nSwapped dataset -> Messidor\nSwapped models -> ConvNeXt + MobileViT\n\"\"\"\n\nimport os\nimport random\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, Sampler\nfrom torchvision import transforms\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score, RocCurveDisplay\nimport timm\nimport matplotlib.pyplot as plt\n\n# ----------------------------\n# CONFIG (Messidor)\n# ----------------------------\nCSV_PATH = \"/kaggle/input/messidor2preprocess/messidor_data.csv\"\nIMG_DIR = \"/kaggle/input/messidor2preprocess/messidor-2/messidor-2/preprocess\"\n\nSEED = 42\ntorch.manual_seed(SEED)\nnp.random.seed(SEED)\nrandom.seed(SEED)\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# SupCon stage\nSUPCON_CLASSES = [1, 2, 3, 4]   # keep same as previous (pretrain on these)\nSUPCON_IMG = 224\nSUPCON_EPOCHS = 50\nSUPCON_BPC = 4\nSUPCON_LR = 1e-4\nSUPCON_CLASS_WEIGHTS = torch.tensor([1.5, 1.0, 1.5, 1.5])  # emphasize some classes\n\n# Classifier stage\nIMG_SIZE = 380\nBATCH_SIZE = 16\nEPOCHS = 40\nLR = 1e-4\nUSE_AMP = True\nMIXUP_ALPHA = 0.4\nSAVE_PATH = \"best_hybrid_supcon234_finetune_messidor.pth\"\nNUM_WORKERS = 2\nPIN_MEMORY = True\n\nFREEZE_SCHEDULE = {\n    2: [],\n    5: [\"model_cnx.stages.3\", \"model_mv.blocks.11\"],\n    8: [\"model_cnx.stages.2\", \"model_mv.blocks.10\"],\n    12: [\"model_cnx.stages.1\", \"model_mv.blocks.9\"]\n}\nFOCAL_GAMMA = 2.0\n\n# ----------------------------\n# Dataset\n# ----------------------------\nclass MessidorDataset(Dataset):\n    def __init__(self, df, img_dir, transform=None, label_col=\"diagnosis\"):\n        self.df = df.reset_index(drop=True)\n        self.img_dir = img_dir\n        self.transform = transform\n        self.label_col = label_col\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        # messidor id_code already contains extension (e.g. 'xyz.jpg')\n        img_path = os.path.join(self.img_dir, row[\"id_code\"])\n        img = Image.open(img_path).convert(\"RGB\")\n        if self.transform:\n            img = self.transform(img)\n        label = int(row[self.label_col])\n        return img, label\n\n# ----------------------------\n# Balanced Batch Sampler\n# ----------------------------\nclass BalancedBatchSampler(Sampler):\n    def __init__(self, groups, bpc):\n        # groups: list of lists of indices per class\n        self.groups = [list(g)[:] for g in groups]\n        self.bpc = int(bpc)\n        self.num_classes = len(groups)\n        # how many batches we can form per epoch\n        self._batches_per_epoch = min(len(g) // self.bpc for g in self.groups) if len(self.groups) > 0 else 0\n\n    def __iter__(self):\n        pools = [g[:] for g in self.groups]\n        for p in pools:\n            random.shuffle(p)\n        ptr = [0] * self.num_classes\n        for _ in range(self._batches_per_epoch):\n            batch = []\n            for c in range(self.num_classes):\n                start = ptr[c]\n                batch.extend(pools[c][start:start + self.bpc])\n                ptr[c] += self.bpc\n            random.shuffle(batch)\n            yield batch\n\n    def __len__(self):\n        return self._batches_per_epoch\n\n# ----------------------------\n# Models (ConvNeXt + MobileViT)\n# ----------------------------\nclass HybridModel(nn.Module):\n    def __init__(self, num_classes=5, pretrained=True, mv_name=\"mobilevitv2_100\", cnx_name=\"convnext_base\"):\n        super().__init__()\n        # create feature-only backbones (num_classes=0)\n        self.model_mv = timm.create_model(mv_name, pretrained=pretrained, num_classes=0, global_pool=\"avg\")\n        self.model_cnx = timm.create_model(cnx_name, pretrained=pretrained, num_classes=0, global_pool=\"avg\")\n\n        # read num_features (timm exposes .num_features for many models)\n        f1 = getattr(self.model_mv, \"num_features\", None)\n        f2 = getattr(self.model_cnx, \"num_features\", None)\n        if f1 is None or f2 is None:\n            # fallback: run a dummy forward with a single image to infer features\n            self.model_mv.eval()\n            self.model_cnx.eval()\n            with torch.no_grad():\n                dummy = torch.randn(1, 3, SUPCON_IMG, SUPCON_IMG)\n                mv_feat = self.model_mv(dummy)\n                cnx_feat = self.model_cnx(dummy)\n            f1 = mv_feat.shape[1]\n            f2 = cnx_feat.shape[1]\n\n        total_features = f1 + f2\n\n        self.classifier = nn.Sequential(\n            nn.Linear(total_features, 512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.3),\n            nn.Linear(512, num_classes)\n        )\n\n    def forward(self, x, return_features=False):\n        f1 = self.model_mv(x)\n        f2 = self.model_cnx(x)\n        # Ensure fused dims align\n        fused = torch.cat([f1, f2], dim=1)\n        if return_features:\n            return fused\n        return self.classifier(fused)\n\n# ----------------------------\n# Losses\n# ----------------------------\nclass WeightedSupConLoss(nn.Module):\n    def __init__(self, temperature=0.07, class_weights=None):\n        super().__init__()\n        self.temperature = temperature\n        self.class_weights = class_weights.float() if class_weights is not None else None\n\n    def forward(self, features, labels):\n        device = features.device\n        B = features.shape[0]\n        features = F.normalize(features, dim=1)\n        labels = labels.view(-1, 1)\n        mask = torch.eq(labels, labels.T).float().to(device)\n\n        logits = torch.matmul(features, features.T) / self.temperature\n        logits_max, _ = torch.max(logits, dim=1, keepdim=True)\n        logits = logits - logits_max.detach()\n\n        diag_mask = torch.eye(B, device=device)\n        exp_logits = torch.exp(logits) * (1 - diag_mask)\n\n        log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True) + 1e-9)\n\n        positives = (mask - diag_mask)\n        denom = positives.sum(1) + 1e-9\n        mean_log_prob_pos = (positives * log_prob).sum(1) / denom\n\n        if self.class_weights is not None:\n            sample_weights = self.class_weights[labels.squeeze().long()].to(device)\n            loss = -(sample_weights * mean_log_prob_pos).mean()\n        else:\n            loss = -mean_log_prob_pos.mean()\n        return loss\n\nclass FocalLoss(nn.Module):\n    def __init__(self, gamma=2.0, alpha=None, reduction=\"mean\"):\n        super().__init__()\n        self.gamma = gamma\n        self.alpha = torch.tensor(alpha, dtype=torch.float) if alpha is not None else None\n        self.reduction = reduction\n\n    def forward(self, inputs, targets):\n        device = inputs.device\n        logpt = F.log_softmax(inputs, dim=1)\n        pt = torch.exp(logpt)\n        targets = targets.long()\n        logpt_t = logpt.gather(1, targets.unsqueeze(1)).squeeze(1)\n        pt_t = pt.gather(1, targets.unsqueeze(1)).squeeze(1)\n        if self.alpha is not None:\n            alpha_t = self.alpha.to(device).gather(0, targets)\n            loss = -alpha_t * ((1 - pt_t) ** self.gamma) * logpt_t\n        else:\n            loss = -((1 - pt_t) ** self.gamma) * logpt_t\n        if self.reduction == \"mean\":\n            return loss.mean()\n        elif self.reduction == \"sum\":\n            return loss.sum()\n        else:\n            return loss\n\n# ----------------------------\n# MixUp\n# ----------------------------\ndef mixup_data(x, y, alpha=MIXUP_ALPHA):\n    lam = np.random.beta(alpha, alpha) if alpha > 0 else 1.0\n    batch_size = x.size(0)\n    index = torch.randperm(batch_size).to(x.device)\n    mixed_x = lam * x + (1.0 - lam) * x[index, :]\n    y_a, y_b = y, y[index]\n    return mixed_x, y_a, y_b, lam\n\ndef mixup_criterion(criterion, pred, y_a, y_b, lam):\n    return lam * criterion(pred, y_a) + (1.0 - lam) * criterion(pred, y_b)\n\n# ----------------------------\n# Data prep (Messidor)\n# ----------------------------\ndf = pd.read_csv(CSV_PATH)\n\n# Ensure labels are ints 0â€“4 (if not already)\nif df[\"diagnosis\"].dtype not in [\"int64\", \"int32\"]:\n    label_map = {cls: i for i, cls in enumerate(sorted(df[\"diagnosis\"].unique()))}\n    df[\"diagnosis\"] = df[\"diagnosis\"].map(label_map)\n\n# SupCon subset\nsupcon_df = df[df[\"diagnosis\"].isin(SUPCON_CLASSES)].reset_index(drop=True)\n# Map to 0..len(SUPCON_CLASSES)-1 for supcon labels\nsupcon_df[\"supcon_label\"] = supcon_df[\"diagnosis\"].map({c: i for i, c in enumerate(SUPCON_CLASSES)})\n\nsupcon_transform = transforms.Compose([\n    transforms.RandomResizedCrop(SUPCON_IMG, scale=(0.8, 1.0)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter(0.2,0.2,0.2),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n])\nsupcon_dataset = MessidorDataset(supcon_df, IMG_DIR, transform=supcon_transform, label_col=\"supcon_label\")\n\nindices_per_class = []\nfor class_idx in range(len(SUPCON_CLASSES)):\n    idxs = supcon_df.index[supcon_df[\"supcon_label\"] == class_idx].tolist()\n    indices_per_class.append(idxs)\n\nbatch_sampler = BalancedBatchSampler(indices_per_class, bpc=SUPCON_BPC)\nsupcon_loader = DataLoader(supcon_dataset, batch_sampler=batch_sampler, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n\n# ----------------------------\n# SupCon Training\n# ----------------------------\nmodel_supcon = HybridModel(num_classes=5, pretrained=True).to(DEVICE)\nsupcon_loss_fn = WeightedSupConLoss(temperature=0.07, class_weights=SUPCON_CLASS_WEIGHTS.to(DEVICE))\noptimizer_supcon = optim.AdamW(model_supcon.parameters(), lr=SUPCON_LR, weight_decay=1e-4)\nscaler_supcon = torch.cuda.amp.GradScaler(enabled=(DEVICE == \"cuda\"))\n\nprint(\"=== SupCon pretraining on classes\", SUPCON_CLASSES, \"===\")\nfor epoch in range(SUPCON_EPOCHS):\n    model_supcon.train()\n    running_loss = 0.0\n    loop = tqdm(supcon_loader, desc=f\"SupCon Epoch {epoch+1}/{SUPCON_EPOCHS}\")\n    for imgs, labels in loop:\n        imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n        optimizer_supcon.zero_grad()\n        with torch.cuda.amp.autocast(enabled=(DEVICE == \"cuda\")):\n            feats = model_supcon(imgs, return_features=True)\n            loss = supcon_loss_fn(feats, labels)\n        scaler_supcon.scale(loss).backward()\n        scaler_supcon.step(optimizer_supcon)\n        scaler_supcon.update()\n        running_loss += loss.item()\n        loop.set_postfix(loss=loss.item())\n    avg_loss = running_loss / max(1, len(supcon_loader))\n    print(f\"SupCon Epoch {epoch+1} | Avg Loss: {avg_loss:.4f}\")\n\ntorch.save(model_supcon.state_dict(), \"hybrid_supcon234_pretrained_messidor.pth\")\nprint(\"Saved SupCon weights.\")\n\n# ----------------------------\n# Classifier Training\n# ----------------------------\ntrain_df, val_df = train_test_split(df, test_size=0.2, stratify=df[\"diagnosis\"], random_state=SEED)\n\ntrain_transform = transforms.Compose([\n    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8,1.0)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n    transforms.RandomRotation(15),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n])\nval_transform = transforms.Compose([\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n])\n\ntrain_dataset = MessidorDataset(train_df, IMG_DIR, transform=train_transform)\nval_dataset = MessidorDataset(val_df, IMG_DIR, transform=val_transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n\nmodel = HybridModel(num_classes=5, pretrained=True).to(DEVICE)\nstate = torch.load(\"hybrid_supcon234_pretrained_messidor.pth\", map_location=DEVICE)\n# load where keys match; we used strict=False to allow shape differences if any\nmodel.load_state_dict(state, strict=False)\n\nclass_counts = train_df[\"diagnosis\"].value_counts().sort_index().values\nclass_weights = (class_counts.sum() / (len(class_counts) * class_counts)).astype(np.float32)\nalpha = torch.tensor(class_weights, dtype=torch.float32)\ncriterion_cls = FocalLoss(gamma=FOCAL_GAMMA, alpha=alpha)\noptimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\nscaler = torch.cuda.amp.GradScaler(enabled=USE_AMP)\n\nif torch.cuda.device_count() > 1:\n    print(\"Using\", torch.cuda.device_count(), \"GPUs.\")\n    model = nn.DataParallel(model)\n\n# By default freeze all except classifier\nfor name, p in model.named_parameters():\n    p.requires_grad = (\"classifier\" in name)\n\ndef gradual_unfreeze(model_obj, epoch, schedule):\n    if epoch in schedule:\n        patterns = schedule[epoch]\n        for name, p in model_obj.named_parameters():\n            if any(pat in name for pat in patterns):\n                p.requires_grad = True\n        print(f\"[Unfreeze] Epoch {epoch}: {patterns}\")\n\n# ----------------------------\n# Track metrics for plotting\n# ----------------------------\ntrain_losses, val_losses = [], []\ntrain_accs, val_accs = [], []\n\nbest_macro_f1 = -1.0\nprint(\"=== Classifier training ===\")\nfor epoch in range(EPOCHS):\n    gradual_unfreeze(model, epoch, FREEZE_SCHEDULE)\n\n    model.train()\n    running_loss = 0.0\n    preds_all, targets_all = [], []\n    for imgs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Train]\", leave=False):\n        imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n        optimizer.zero_grad()\n        imgs_mixed, ya, yb, lam = mixup_data(imgs, labels)\n        with torch.cuda.amp.autocast(enabled=USE_AMP):\n            outputs = model(imgs_mixed)\n            loss = mixup_criterion(criterion_cls, outputs, ya, yb, lam)\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        running_loss += loss.item()\n        preds_all.extend(outputs.argmax(1).detach().cpu().numpy())\n        targets_all.extend(labels.cpu().numpy())\n    train_acc = accuracy_score(targets_all, preds_all)\n    train_loss_avg = running_loss / max(1, len(train_loader))\n    train_losses.append(train_loss_avg)\n    train_accs.append(train_acc)\n\n    model.eval()\n    val_preds, val_targets = [], []\n    val_outputs_all = []\n    val_loss_accum = 0.0\n    with torch.no_grad():\n        for imgs, labels in tqdm(val_loader, desc=\"Validation\", leave=False):\n            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n            with torch.cuda.amp.autocast(enabled=USE_AMP):\n                outputs = model(imgs)\n                loss_v = criterion_cls(outputs, labels)\n            val_loss_accum += loss_v.item()\n            val_preds.extend(outputs.argmax(1).cpu().numpy())\n            val_targets.extend(labels.cpu().numpy())\n            val_outputs_all.append(outputs.softmax(dim=1).cpu())\n    val_loss_avg = val_loss_accum / max(1, len(val_loader))\n    val_losses.append(val_loss_avg)\n    val_acc = accuracy_score(val_targets, val_preds)\n    val_accs.append(val_acc)\n\n    from sklearn.metrics import f1_score\n    macro_f1 = f1_score(val_targets, val_preds, average=\"macro\")\n    print(f\"Epoch {epoch+1} | Train Loss {train_loss_avg:.4f} Acc {train_acc:.4f} | Val Loss {val_loss_avg:.4f} Acc {val_acc:.4f} | F1 {macro_f1:.4f}\")\n\n    if macro_f1 > best_macro_f1:\n        best_macro_f1 = macro_f1\n        if isinstance(model, nn.DataParallel):\n            torch.save(model.module.state_dict(), SAVE_PATH)\n        else:\n            torch.save(model.state_dict(), SAVE_PATH)\n        print(f\"Saved best model (F1={macro_f1:.4f})\")\n\n    scheduler.step()\n\n# ----------------------------\n# Plot metrics\n# ----------------------------\nplt.figure(figsize=(12,5))\nplt.subplot(1,2,1)\nplt.plot(range(1,EPOCHS+1), train_losses, label=\"Train Loss\")\nplt.plot(range(1,EPOCHS+1), val_losses, label=\"Val Loss\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.title(\"Loss vs Epoch\")\nplt.legend()\nplt.subplot(1,2,2)\nplt.plot(range(1,EPOCHS+1), train_accs, label=\"Train Acc\")\nplt.plot(range(1,EPOCHS+1), val_accs, label=\"Val Acc\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Accuracy vs Epoch\")\nplt.legend()\nplt.show()\n\n# ----------------------------\n# Final eval & ROC-AUC curves\n# ----------------------------\nbest_state = torch.load(SAVE_PATH, map_location=DEVICE)\nfinal_model = HybridModel(num_classes=5, pretrained=True).to(DEVICE)\nfinal_model.load_state_dict(best_state, strict=False)\nfinal_model.eval()\n\nval_preds, val_targets = [], []\nval_probs = []\nwith torch.no_grad():\n    for imgs, labels in val_loader:\n        imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n        outputs = final_model(imgs)\n        val_preds.extend(outputs.argmax(1).cpu().numpy())\n        val_targets.extend(labels.cpu().numpy())\n        val_probs.append(outputs.softmax(dim=1).cpu())\nval_probs = torch.cat(val_probs, dim=0).numpy()\nval_targets_np = np.array(val_targets)\n\nprint(\"\\nFinal Report:\")\nprint(classification_report(val_targets, val_preds, digits=4))\ncm = confusion_matrix(val_targets, val_preds)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(range(5)))\ndisp.plot(cmap=\"Blues\", xticks_rotation=45)\nplt.show()\n\n# ROC-AUC per class\nplt.figure(figsize=(10,8))\nfor i in range(5):\n    RocCurveDisplay.from_predictions((val_targets_np==i).astype(int), val_probs[:,i], name=f\"Class {i}\")\nplt.plot([0,1],[0,1],\"k--\")\nplt.title(\"ROC Curves per Class\")\nplt.show()\n\n# ----------------------------\n# Visualize predictions on validation images\n# ----------------------------\ndef show_predictions(model, dataset, num_images=8):\n    model.eval()\n    indices = np.random.choice(len(dataset), size=num_images, replace=False)\n    plt.figure(figsize=(15,5))\n    for i, idx in enumerate(indices):\n        img, label = dataset[idx]\n        inp = img.unsqueeze(0).to(DEVICE)\n        with torch.no_grad():\n            out = model(inp)\n            pred = out.argmax(1).item()\n        img_np = img.permute(1,2,0).numpy()\n        img_np = np.clip(img_np * [0.229,0.224,0.225] + [0.485,0.456,0.406], 0,1)\n        plt.subplot(2, num_images//2, i+1)\n        plt.imshow(img_np)\n        plt.title(f\"GT: {label} | Pred: {pred}\")\n        plt.axis(\"off\")\n    plt.show()\n\nshow_predictions(final_model, val_dataset, num_images=8)\n\ntorch.save(final_model.state_dict(), SAVE_PATH.replace(\".pth\", \"_final.pth\"))\nprint(\"Final model saved.\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-03T20:36:15.388861Z","iopub.execute_input":"2025-10-03T20:36:15.389670Z","iopub.status.idle":"2025-10-03T21:24:39.559446Z","shell.execute_reply.started":"2025-10-03T20:36:15.389637Z","shell.execute_reply":"2025-10-03T21:24:39.558024Z"}},"outputs":[],"execution_count":null}]}