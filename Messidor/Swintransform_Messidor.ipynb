{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2819730,"sourceType":"datasetVersion","datasetId":1723812}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report\nimport pandas as pd\nfrom PIL import Image\nimport timm\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport random\n\n# ----------------------------\n# Config\n# ----------------------------\nIMG_SIZE = 224   # Swin is trained with 224x224\nBATCH_SIZE = 32\nEPOCHS = 20\nLR = 1e-4\nSEED = 42\n\nDATA_CSV = \"/kaggle/input/messidor2preprocess/messidor_data.csv\"\nIMG_DIR = \"/kaggle/input/messidor2preprocess/messidor-2/messidor-2/preprocess\"\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# reproducibility\ntorch.manual_seed(SEED)\nnp.random.seed(SEED)\nrandom.seed(SEED)\nif DEVICE == \"cuda\":\n    torch.cuda.manual_seed_all(SEED)\n\n# ----------------------------\n# Dataset\n# ----------------------------\nclass MessidorDataset(Dataset):\n    def __init__(self, df, img_dir, transform=None):\n        self.df = df.reset_index(drop=True)\n        self.img_dir = img_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img_id = row['id_code']       # already has extension like \"xyz.jpg\"\n        label = int(row['diagnosis'])\n        img_path = os.path.join(self.img_dir, img_id)\n        image = Image.open(img_path).convert(\"RGB\")\n        if self.transform:\n            image = self.transform(image)\n        return image, label\n\n\nif __name__ == \"__main__\":\n    # ----------------------------\n    # Data Prep\n    # ----------------------------\n    df = pd.read_csv(DATA_CSV)\n\n    # Ensure labels are ints 0â€“4\n    if df[\"diagnosis\"].dtype not in [\"int64\", \"int32\"]:\n        label_map = {cls: i for i, cls in enumerate(sorted(df[\"diagnosis\"].unique()))}\n        df[\"diagnosis\"] = df[\"diagnosis\"].map(label_map)\n\n    print(\"Unique labels:\", np.unique(df[\"diagnosis\"]))\n    print(\"Label distribution:\\n\", df[\"diagnosis\"].value_counts())\n\n    train_df, val_df = train_test_split(\n        df, test_size=0.2, stratify=df[\"diagnosis\"], random_state=SEED\n    )\n\n    train_transform = transforms.Compose([\n        transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0)),\n        transforms.RandomHorizontalFlip(),\n        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n        transforms.RandomRotation(15),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406],\n                             [0.229, 0.224, 0.225]),\n    ])\n\n    val_transform = transforms.Compose([\n        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406],\n                             [0.229, 0.224, 0.225]),\n    ])\n\n    train_dataset = MessidorDataset(train_df, IMG_DIR, transform=train_transform)\n    val_dataset = MessidorDataset(val_df, IMG_DIR, transform=val_transform)\n\n    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n                              num_workers=4, pin_memory=True)\n    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n                            num_workers=4, pin_memory=True)\n\n    # ----------------------------\n    # Model (Swin Transformer)\n    # ----------------------------\n    model_name = \"swin_base_patch4_window7_224\"\n    print(f\"Creating model: {model_name}\")\n    model = timm.create_model(model_name, pretrained=True, num_classes=5)\n\n    if torch.cuda.device_count() > 1:\n        print(f\"Using {torch.cuda.device_count()} GPUs via DataParallel.\")\n        model = nn.DataParallel(model)\n\n    model = model.to(DEVICE)\n\n    # ----------------------------\n    # Loss, Optimizer, Scheduler, AMP\n    # ----------------------------\n    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n    optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n    scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE == \"cuda\"))\n\n    # ----------------------------\n    # Training loop\n    # ----------------------------\n    best_acc = 0.0\n    best_ckpt = \"/kaggle/working/best_swin.pth\"\n    print(f\"Starting training for {EPOCHS} epochs. Steps/epoch={len(train_loader)}, LR={LR}\")\n\n    for epoch in range(EPOCHS):\n        model.train()\n        train_loss = 0.0\n        train_preds, train_targets = [], []\n        train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Train]\", leave=False)\n\n        for imgs, labels in train_bar:\n            imgs = imgs.to(DEVICE, non_blocking=True)\n            labels = labels.to(DEVICE, non_blocking=True)\n\n            optimizer.zero_grad()\n            with torch.amp.autocast(device_type=\"cuda\", enabled=(DEVICE == \"cuda\")):\n                outputs = model(imgs)\n                loss = criterion(outputs, labels)\n\n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n\n            train_loss += loss.item() * imgs.size(0)\n            preds = outputs.argmax(dim=1).detach().cpu().numpy()\n            train_preds.extend(preds)\n            train_targets.extend(labels.cpu().numpy())\n            train_bar.set_postfix(loss=loss.item())\n\n        train_loss /= len(train_loader.dataset)\n        train_acc = accuracy_score(train_targets, train_preds)\n\n        # ----------------------------\n        # Validation\n        # ----------------------------\n        model.eval()\n        val_loss = 0.0\n        val_preds, val_targets = [], []\n        val_bar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Val]\", leave=False)\n        with torch.no_grad():\n            for imgs, labels in val_bar:\n                imgs = imgs.to(DEVICE, non_blocking=True)\n                labels = labels.to(DEVICE, non_blocking=True)\n                with torch.amp.autocast(device_type=\"cuda\", enabled=(DEVICE == \"cuda\")):\n                    outputs = model(imgs)\n                    loss = criterion(outputs, labels)\n\n                val_loss += loss.item() * imgs.size(0)\n                preds = outputs.argmax(dim=1).detach().cpu().numpy()\n                val_preds.extend(preds)\n                val_targets.extend(labels.cpu().numpy())\n                val_bar.set_postfix(loss=loss.item())\n\n        val_loss /= len(val_loader.dataset)\n        val_acc = accuracy_score(val_targets, val_preds)\n        val_f1 = f1_score(val_targets, val_preds, average=\"weighted\")\n\n        print(f\"Epoch {epoch+1}/{EPOCHS} | \"\n              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}\")\n\n        scheduler.step()\n\n        if val_acc > best_acc:\n            best_acc = val_acc\n            state_dict_to_save = model.module.state_dict() if hasattr(model, \"module\") else model.state_dict()\n            torch.save(state_dict_to_save, best_ckpt)\n            print(f\"âœ… New best model saved. Best Val Acc: {best_acc:.4f}\")\n\n    print(f\"\\nâœ… Training complete. Best Val Acc: {best_acc:.4f}\")\n\n    # ----------------------------\n    # Evaluation (load best)\n    # ----------------------------\n    state_dict = torch.load(best_ckpt, map_location=DEVICE)\n    if hasattr(model, \"module\"):\n        model.module.load_state_dict(state_dict)\n    else:\n        model.load_state_dict(state_dict)\n    model.eval()\n\n    all_preds, all_labels = [], []\n    with torch.no_grad():\n        for imgs, labels in val_loader:\n            imgs = imgs.to(DEVICE)\n            labels = labels.to(DEVICE)\n            with torch.amp.autocast(device_type=\"cuda\", enabled=(DEVICE == \"cuda\")):\n                outputs = model(imgs)\n            _, preds = torch.max(outputs, 1)\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    acc = accuracy_score(all_labels, all_preds)\n    f1 = f1_score(all_labels, all_preds, average=\"weighted\")\n    precision = precision_score(all_labels, all_preds, average=\"weighted\", zero_division=0)\n    recall = recall_score(all_labels, all_preds, average=\"weighted\", zero_division=0)\n    cm = confusion_matrix(all_labels, all_preds)\n\n    print(f\"\\nðŸ“Š Accuracy: {acc:.4f}\")\n    print(f\"ðŸ“Š F1 Score: {f1:.4f}\")\n    print(f\"ðŸ“Š Precision: {precision:.4f}\")\n    print(f\"ðŸ“Š Recall: {recall:.4f}\")\n    print(\"\\nClassification Report:\\n\", classification_report(all_labels, all_preds, zero_division=0))\n\n    plt.figure(figsize=(8,6))\n    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n                xticklabels=[0,1,2,3,4], yticklabels=[0,1,2,3,4])\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"True\")\n    plt.title(\"Swin Transformer Confusion Matrix\")\n    plt.tight_layout()\n    plt.show()\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-03T17:05:09.321219Z","iopub.execute_input":"2025-10-03T17:05:09.321498Z","iopub.status.idle":"2025-10-03T17:05:20.543159Z","shell.execute_reply.started":"2025-10-03T17:05:09.321478Z","shell.execute_reply":"2025-10-03T17:05:20.542178Z"}},"outputs":[],"execution_count":null}]}