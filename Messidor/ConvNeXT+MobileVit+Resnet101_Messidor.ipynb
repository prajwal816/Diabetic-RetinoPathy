{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2819730,"sourceType":"datasetVersion","datasetId":1723812}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# hybrid_supcon_134_balanced_viz_messidor_convnext_mobilevit_resnet.py\n\"\"\"\nSupCon pretrain on classes [1,3,4] with balanced batches + weighted SupCon loss,\nthen fine-tune whole hybrid model on all 5 classes with MixUp + Focal Loss,\ngradual unfreeze and multi-GPU DataParallel for the classifier stage.\n\nDataset -> Messidor\nModels -> ConvNeXt + MobileViT + ResNet101\n\"\"\"\n\nimport os\nimport random\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, Sampler\nfrom torchvision import transforms\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import (\n    accuracy_score, classification_report, confusion_matrix,\n    ConfusionMatrixDisplay, f1_score\n)\nimport timm\nimport matplotlib.pyplot as plt\n\n# ----------------------------\n# CONFIG (Messidor)\n# ----------------------------\nCSV_PATH = \"/kaggle/input/messidor2preprocess/messidor_data.csv\"\nIMG_DIR = \"/kaggle/input/messidor2preprocess/messidor-2/messidor-2/preprocess\"\n\nSEED = 42\ntorch.manual_seed(SEED)\nnp.random.seed(SEED)\nrandom.seed(SEED)\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# SupCon stage\nSUPCON_CLASSES = [1, 3, 4]  # ✅ changed from [1,2,3,4]\nSUPCON_IMG = 224\nSUPCON_EPOCHS = 50\nSUPCON_BPC = 4\nSUPCON_LR = 1e-4\nSUPCON_CLASS_WEIGHTS = torch.tensor([1.5, 1.0, 1.5])  # ✅ match new 3-class config\n\n# Classifier stage\nIMG_SIZE = 380\nBATCH_SIZE = 16\nEPOCHS = 40\nLR = 1e-4\nUSE_AMP = True\nMIXUP_ALPHA = 0.4\nSAVE_PATH = \"best_hybrid_supcon134_finetune_messidor_3models.pth\"\nNUM_WORKERS = 2\nPIN_MEMORY = True\n\nFREEZE_SCHEDULE = {\n    2: [],\n    5: [\"model_cnx.stages.3\", \"model_mv.blocks.11\", \"model_res.layer4\"],\n    8: [\"model_cnx.stages.2\", \"model_mv.blocks.10\", \"model_res.layer3\"],\n    12: [\"model_cnx.stages.1\", \"model_mv.blocks.9\", \"model_res.layer2\"]\n}\nFOCAL_GAMMA = 2.0\n\n# ----------------------------\n# Dataset\n# ----------------------------\nclass MessidorDataset(Dataset):\n    def __init__(self, df, img_dir, transform=None, label_col=\"diagnosis\"):\n        self.df = df.reset_index(drop=True)\n        self.img_dir = img_dir\n        self.transform = transform\n        self.label_col = label_col\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img_path = os.path.join(self.img_dir, row[\"id_code\"])\n        img = Image.open(img_path).convert(\"RGB\")\n        if self.transform:\n            img = self.transform(img)\n        label = int(row[self.label_col])\n        return img, label\n\n# ----------------------------\n# Balanced Batch Sampler\n# ----------------------------\nclass BalancedBatchSampler(Sampler):\n    def __init__(self, groups, bpc):\n        self.groups = [list(g)[:] for g in groups]\n        self.bpc = int(bpc)\n        self.num_classes = len(groups)\n        self._batches_per_epoch = min(len(g) // self.bpc for g in self.groups) if len(self.groups) > 0 else 0\n\n    def __iter__(self):\n        pools = [g[:] for g in self.groups]\n        for p in pools:\n            random.shuffle(p)\n        ptr = [0] * self.num_classes\n        for _ in range(self._batches_per_epoch):\n            batch = []\n            for c in range(self.num_classes):\n                start = ptr[c]\n                batch.extend(pools[c][start:start + self.bpc])\n                ptr[c] += self.bpc\n            random.shuffle(batch)\n            yield batch\n\n    def __len__(self):\n        return self._batches_per_epoch\n\n# ----------------------------\n# Hybrid Model\n# ----------------------------\nclass HybridModel(nn.Module):\n    def __init__(self, num_classes=5, pretrained=True,\n                 mv_name=\"mobilevitv2_100\", cnx_name=\"convnext_base\", res_name=\"resnet101\"):\n        super().__init__()\n        self.model_mv = timm.create_model(mv_name, pretrained=pretrained, num_classes=0, global_pool=\"avg\")\n        self.model_cnx = timm.create_model(cnx_name, pretrained=pretrained, num_classes=0, global_pool=\"avg\")\n        self.model_res = timm.create_model(res_name, pretrained=pretrained, num_classes=0, global_pool=\"avg\")\n\n        with torch.no_grad():\n            dummy = torch.randn(1, 3, SUPCON_IMG, SUPCON_IMG)\n            f1 = self.model_mv(dummy).shape[1]\n            f2 = self.model_cnx(dummy).shape[1]\n            f3 = self.model_res(dummy).shape[1]\n        total_features = f1 + f2 + f3\n\n        self.classifier = nn.Sequential(\n            nn.Linear(total_features, 512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.3),\n            nn.Linear(512, num_classes)\n        )\n\n    def forward(self, x, return_features=False):\n        f1 = self.model_mv(x)\n        f2 = self.model_cnx(x)\n        f3 = self.model_res(x)\n        fused = torch.cat([f1, f2, f3], dim=1)\n        if return_features:\n            return fused\n        return self.classifier(fused)\n\n# ----------------------------\n# Losses\n# ----------------------------\nclass WeightedSupConLoss(nn.Module):\n    def __init__(self, temperature=0.07, class_weights=None):\n        super().__init__()\n        self.temperature = temperature\n        self.class_weights = class_weights.float() if class_weights is not None else None\n\n    def forward(self, features, labels):\n        device = features.device\n        B = features.shape[0]\n        features = F.normalize(features, dim=1)\n        labels = labels.view(-1, 1)\n        mask = torch.eq(labels, labels.T).float().to(device)\n\n        logits = torch.matmul(features, features.T) / self.temperature\n        logits_max, _ = torch.max(logits, dim=1, keepdim=True)\n        logits = logits - logits_max.detach()\n\n        diag_mask = torch.eye(B, device=device)\n        exp_logits = torch.exp(logits) * (1 - diag_mask)\n        log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True) + 1e-9)\n        positives = (mask - diag_mask)\n        denom = positives.sum(1) + 1e-9\n        mean_log_prob_pos = (positives * log_prob).sum(1) / denom\n\n        if self.class_weights is not None:\n            sample_weights = self.class_weights[labels.squeeze().long()].to(device)\n            loss = -(sample_weights * mean_log_prob_pos).mean()\n        else:\n            loss = -mean_log_prob_pos.mean()\n        return loss\n\nclass FocalLoss(nn.Module):\n    def __init__(self, gamma=2.0, alpha=None, reduction=\"mean\"):\n        super().__init__()\n        self.gamma = gamma\n        self.alpha = torch.tensor(alpha, dtype=torch.float) if alpha is not None else None\n        self.reduction = reduction\n\n    def forward(self, inputs, targets):\n        device = inputs.device\n        logpt = F.log_softmax(inputs, dim=1)\n        pt = torch.exp(logpt)\n        targets = targets.long()\n        logpt_t = logpt.gather(1, targets.unsqueeze(1)).squeeze(1)\n        pt_t = pt.gather(1, targets.unsqueeze(1)).squeeze(1)\n        if self.alpha is not None:\n            alpha_t = self.alpha.to(device).gather(0, targets)\n            loss = -alpha_t * ((1 - pt_t) ** self.gamma) * logpt_t\n        else:\n            loss = -((1 - pt_t) ** self.gamma) * logpt_t\n        if self.reduction == \"mean\":\n            return loss.mean()\n        elif self.reduction == \"sum\":\n            return loss.sum()\n        else:\n            return loss\n\n# ----------------------------\n# MixUp\n# ----------------------------\ndef mixup_data(x, y, alpha=MIXUP_ALPHA):\n    lam = np.random.beta(alpha, alpha) if alpha > 0 else 1.0\n    batch_size = x.size(0)\n    index = torch.randperm(batch_size).to(x.device)\n    mixed_x = lam * x + (1.0 - lam) * x[index, :]\n    y_a, y_b = y, y[index]\n    return mixed_x, y_a, y_b, lam\n\ndef mixup_criterion(criterion, pred, y_a, y_b, lam):\n    return lam * criterion(pred, y_a) + (1.0 - lam) * criterion(pred, y_b)\n\n# ----------------------------\n# Data prep (Messidor)\n# ----------------------------\ndf = pd.read_csv(CSV_PATH)\n\nif df[\"diagnosis\"].dtype not in [\"int64\", \"int32\"]:\n    label_map = {cls: i for i, cls in enumerate(sorted(df[\"diagnosis\"].unique()))}\n    df[\"diagnosis\"] = df[\"diagnosis\"].map(label_map)\n\nsupcon_df = df[df[\"diagnosis\"].isin(SUPCON_CLASSES)].reset_index(drop=True)\nsupcon_df[\"supcon_label\"] = supcon_df[\"diagnosis\"].map({c: i for i, c in enumerate(SUPCON_CLASSES)})\n\nsupcon_transform = transforms.Compose([\n    transforms.RandomResizedCrop(SUPCON_IMG, scale=(0.8, 1.0)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter(0.2,0.2,0.2),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n])\nsupcon_dataset = MessidorDataset(supcon_df, IMG_DIR, transform=supcon_transform, label_col=\"supcon_label\")\n\nindices_per_class = []\nfor class_idx in range(len(SUPCON_CLASSES)):\n    idxs = supcon_df.index[supcon_df[\"supcon_label\"] == class_idx].tolist()\n    indices_per_class.append(idxs)\n\nbatch_sampler = BalancedBatchSampler(indices_per_class, bpc=SUPCON_BPC)\nsupcon_loader = DataLoader(supcon_dataset, batch_sampler=batch_sampler, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n\n# ----------------------------\n# SupCon Training\n# ----------------------------\nmodel_supcon = HybridModel(num_classes=5, pretrained=True).to(DEVICE)\nsupcon_loss_fn = WeightedSupConLoss(temperature=0.07, class_weights=SUPCON_CLASS_WEIGHTS.to(DEVICE))\noptimizer_supcon = optim.AdamW(model_supcon.parameters(), lr=SUPCON_LR, weight_decay=1e-4)\nscaler_supcon = torch.cuda.amp.GradScaler(enabled=(DEVICE == \"cuda\"))\n\nprint(\"=== SupCon pretraining on classes\", SUPCON_CLASSES, \"===\")\nfor epoch in range(SUPCON_EPOCHS):\n    model_supcon.train()\n    running_loss = 0.0\n    loop = tqdm(supcon_loader, desc=f\"SupCon Epoch {epoch+1}/{SUPCON_EPOCHS}\")\n    for imgs, labels in loop:\n        imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n        optimizer_supcon.zero_grad()\n        with torch.cuda.amp.autocast(enabled=(DEVICE == \"cuda\")):\n            feats = model_supcon(imgs, return_features=True)\n            loss = supcon_loss_fn(feats, labels)\n        scaler_supcon.scale(loss).backward()\n        scaler_supcon.step(optimizer_supcon)\n        scaler_supcon.update()\n        running_loss += loss.item()\n        loop.set_postfix(loss=loss.item())\n    avg_loss = running_loss / max(1, len(supcon_loader))\n    print(f\"SupCon Epoch {epoch+1} | Avg Loss: {avg_loss:.4f}\")\n\ntorch.save(model_supcon.state_dict(), \"hybrid_supcon134_pretrained_messidor_3models.pth\")\nprint(\"Saved SupCon weights.\")\n\n# ----------------------------\n# Classifier Training\n# ----------------------------\ntrain_df, val_df = train_test_split(df, test_size=0.2, stratify=df[\"diagnosis\"], random_state=SEED)\n\ntrain_transform = transforms.Compose([\n    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8,1.0)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n    transforms.RandomRotation(15),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n])\nval_transform = transforms.Compose([\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n])\n\ntrain_dataset = MessidorDataset(train_df, IMG_DIR, transform=train_transform)\nval_dataset = MessidorDataset(val_df, IMG_DIR, transform=val_transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n\nmodel = HybridModel(num_classes=5, pretrained=True).to(DEVICE)\nstate = torch.load(\"hybrid_supcon134_pretrained_messidor_3models.pth\", map_location=DEVICE)\nmodel.load_state_dict(state, strict=False)\n\nclass_counts = train_df[\"diagnosis\"].value_counts().sort_index().values\nclass_weights = (class_counts.sum() / (len(class_counts) * class_counts)).astype(np.float32)\nalpha = torch.tensor(class_weights, dtype=torch.float32)\ncriterion_cls = FocalLoss(gamma=FOCAL_GAMMA, alpha=alpha)\noptimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\nscaler = torch.cuda.amp.GradScaler(enabled=USE_AMP)\n\nif torch.cuda.device_count() > 1:\n    print(\"Using\", torch.cuda.device_count(), \"GPUs.\")\n    model = nn.DataParallel(model)\n\nfor name, p in model.named_parameters():\n    p.requires_grad = (\"classifier\" in name)\n\ndef gradual_unfreeze(model_obj, epoch, schedule):\n    if epoch in schedule:\n        patterns = schedule[epoch]\n        for name, p in model_obj.named_parameters():\n            if any(pat in name for pat in patterns):\n                p.requires_grad = True\n        print(f\"[Unfreeze] Epoch {epoch}: {patterns}\")\n\n# ----------------------------\n# Training Loop\n# ----------------------------\ntrain_losses, val_losses, train_accs, val_accs = [], [], [], []\nbest_macro_f1 = -1.0\n\nprint(\"=== Classifier training ===\")\nfor epoch in range(EPOCHS):\n    gradual_unfreeze(model, epoch, FREEZE_SCHEDULE)\n\n    model.train()\n    running_loss = 0.0\n    preds_all, targets_all = [], []\n    for imgs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Train]\", leave=False):\n        imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n        optimizer.zero_grad()\n        imgs_mixed, ya, yb, lam = mixup_data(imgs, labels)\n        with torch.cuda.amp.autocast(enabled=USE_AMP):\n            outputs = model(imgs_mixed)\n            loss = mixup_criterion(criterion_cls, outputs, ya, yb, lam)\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        running_loss += loss.item()\n        preds_all.extend(outputs.argmax(1).detach().cpu().numpy())\n        targets_all.extend(labels.cpu().numpy())\n    train_acc = accuracy_score(targets_all, preds_all)\n    train_loss_avg = running_loss / max(1, len(train_loader))\n    train_losses.append(train_loss_avg)\n    train_accs.append(train_acc)\n\n    model.eval()\n    val_preds, val_targets = [], []\n    val_loss_accum = 0.0\n    with torch.no_grad():\n        for imgs, labels in tqdm(val_loader, desc=\"Validation\", leave=False):\n            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n            with torch.cuda.amp.autocast(enabled=USE_AMP):\n                outputs = model(imgs)\n                loss_v = criterion_cls(outputs, labels)\n            val_loss_accum += loss_v.item()\n            val_preds.extend(outputs.argmax(1).cpu().numpy())\n            val_targets.extend(labels.cpu().numpy())\n    val_loss_avg = val_loss_accum / max(1, len(val_loader))\n    val_losses.append(val_loss_avg)\n    val_acc = accuracy_score(val_targets, val_preds)\n    val_accs.append(val_acc)\n    macro_f1 = f1_score(val_targets, val_preds, average=\"macro\")\n\n    print(f\"Epoch {epoch+1} | Train Loss {train_loss_avg:.4f} Acc {train_acc:.4f} | Val Loss {val_loss_avg:.4f} Acc {val_acc:.4f} | F1 {macro_f1:.4f}\")\n\n    if macro_f1 > best_macro_f1:\n        best_macro_f1 = macro_f1\n        torch.save(model.module.state_dict() if isinstance(model, nn.DataParallel) else model.state_dict(), SAVE_PATH)\n        print(f\"Saved best model (F1={macro_f1:.4f})\")\n\n    scheduler.step()\n\n# ----------------------------\n# Plot metrics\n# ----------------------------\nplt.figure(figsize=(12,5))\nplt.subplot(1,2,1)\nplt.plot(range(1,EPOCHS+1), train_losses, label=\"Train Loss\")\nplt.plot(range(1,EPOCHS+1), val_losses, label=\"Val Loss\")\nplt.legend(); plt.title(\"Loss Curve\")\n\nplt.subplot(1,2,2)\nplt.plot(range(1,EPOCHS+1), train_accs, label=\"Train Acc\")\nplt.plot(range(1,EPOCHS+1), val_accs, label=\"Val Acc\")\nplt.legend(); plt.title(\"Accuracy Curve\")\nplt.tight_layout()\nplt.show()\n\n# ----------------------------\n# Final Evaluation\n# ----------------------------\nbest_model = HybridModel(num_classes=5, pretrained=False).to(DEVICE)\nbest_model.load_state_dict(torch.load(SAVE_PATH, map_location=DEVICE))\nbest_model.eval()\n\nval_preds, val_targets = [], []\nwith torch.no_grad():\n    for imgs, labels in tqdm(val_loader, desc=\"Final Evaluation\"):\n        imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n        outputs = best_model(imgs)\n        val_preds.extend(outputs.argmax(1).cpu().numpy())\n        val_targets.extend(labels.cpu().numpy())\n\nprint(classification_report(val_targets, val_preds))\ncm = confusion_matrix(val_targets, val_preds)\nConfusionMatrixDisplay(cm).plot(cmap=\"Blues\")\nplt.show()\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-04T17:52:12.043525Z","iopub.execute_input":"2025-10-04T17:52:12.043905Z","iopub.status.idle":"2025-10-04T17:54:49.673487Z","shell.execute_reply.started":"2025-10-04T17:52:12.043870Z","shell.execute_reply":"2025-10-04T17:54:49.672607Z"}},"outputs":[],"execution_count":null}]}