{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2819730,"sourceType":"datasetVersion","datasetId":1723812}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms, models\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report\nimport pandas as pd\nfrom PIL import Image\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# ----------------------------\n# Config\n# ----------------------------\nIMG_SIZE = 380\nBATCH_SIZE = 32\nEPOCHS = 25\nLR = 1e-4\nSEED = 42\n\nDATA_CSV = \"/kaggle/input/messidor2preprocess/messidor_data.csv\"\nIMG_DIR = \"/kaggle/input/messidor2preprocess/messidor-2/messidor-2/preprocess\"\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\ntorch.manual_seed(SEED)\n\n# ----------------------------\n# Dataset\n# ----------------------------\nclass MessidorDataset(Dataset):\n    def __init__(self, df, img_dir, transform=None):\n        self.df = df\n        self.img_dir = img_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img_id = row['id_code']\n        label = row['diagnosis']\n        img_path = os.path.join(self.img_dir, img_id)\n        image = Image.open(img_path).convert(\"RGB\")\n        if self.transform:\n            image = self.transform(image)\n        return image, label\n\n# ----------------------------\n# Data Prep\n# ----------------------------\ndf = pd.read_csv(DATA_CSV)\ntrain_df, val_df = train_test_split(df, test_size=0.2, stratify=df[\"diagnosis\"], random_state=SEED)\n\ntrain_transform = transforms.Compose([\n    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n    transforms.RandomRotation(20),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],\n                         [0.229, 0.224, 0.225]),\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],\n                         [0.229, 0.224, 0.225]),\n])\n\ntrain_dataset = MessidorDataset(train_df, IMG_DIR, transform=train_transform)\nval_dataset = MessidorDataset(val_df, IMG_DIR, transform=val_transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n\n# ----------------------------\n# Model\n# ----------------------------\nmodel = models.resnet101(pretrained=True)\nmodel.fc = nn.Linear(model.fc.in_features, 5)\n\nif torch.cuda.device_count() > 1:\n    print(f\"Using {torch.cuda.device_count()} GPUs\")\n    model = nn.DataParallel(model)\nmodel = model.to(DEVICE)\n\n# ----------------------------\n# Loss and Optimizer\n# ----------------------------\nclass FocalLoss(nn.Module):\n    def __init__(self, gamma=2.0, alpha=None, reduction='mean'):\n        super(FocalLoss, self).__init__()\n        self.gamma = gamma\n        self.alpha = alpha\n        self.reduction = reduction\n        self.ce = nn.CrossEntropyLoss(weight=alpha, reduction='none')\n\n    def forward(self, input, target):\n        logp = self.ce(input, target)\n        p = torch.exp(-logp)\n        loss = (1 - p) ** self.gamma * logp\n        if self.reduction == 'mean':\n            return loss.mean()\n        else:\n            return loss.sum()\n\ncriterion = FocalLoss()\noptimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\nscheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=1)\nscaler = torch.cuda.amp.GradScaler()\n\n# ----------------------------\n# Training Loop\n# ----------------------------\nbest_acc = 0.0\nfor epoch in range(EPOCHS):\n    model.train()\n    train_loss, train_preds, train_targets = 0, [], []\n    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Train]\", leave=False)\n    \n    for imgs, labels in train_bar:\n        imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n        optimizer.zero_grad()\n        with torch.cuda.amp.autocast():\n            outputs = model(imgs)\n            loss = criterion(outputs, labels)\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        train_loss += loss.item()\n        preds = outputs.argmax(1).detach().cpu().numpy()\n        train_preds.extend(preds)\n        train_targets.extend(labels.cpu().numpy())\n        train_bar.set_postfix(loss=loss.item())\n\n    train_acc = accuracy_score(train_targets, train_preds)\n\n    model.eval()\n    val_loss, val_preds, val_targets = 0, [], []\n    val_bar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Val]\", leave=False)\n    with torch.no_grad():\n        for imgs, labels in val_bar:\n            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n            with torch.cuda.amp.autocast():\n                outputs = model(imgs)\n                loss = criterion(outputs, labels)\n            val_loss += loss.item()\n            preds = outputs.argmax(1).detach().cpu().numpy()\n            val_preds.extend(preds)\n            val_targets.extend(labels.cpu().numpy())\n            val_bar.set_postfix(loss=loss.item())\n\n    val_acc = accuracy_score(val_targets, val_preds)\n    print(f\"Epoch {epoch+1}/{EPOCHS} | \"\n          f\"Train Loss: {train_loss/len(train_loader):.4f}, \"\n          f\"Train Acc: {train_acc:.4f} | \"\n          f\"Val Loss: {val_loss/len(val_loader):.4f}, \"\n          f\"Val Acc: {val_acc:.4f}\")\n\n    scheduler.step()\n\n    if val_acc > best_acc:\n        best_acc = val_acc\n        torch.save(model.state_dict(), \"/kaggle/working/best_resnet101.pth\")\n\n# ----------------------------\n# Evaluation\n# ----------------------------\nmodel.load_state_dict(torch.load(\"/kaggle/working/best_resnet101.pth\", map_location=DEVICE))\nmodel.eval()\nall_preds, all_labels = [], []\n\nwith torch.no_grad():\n    for imgs, labels in val_loader:\n        imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n        with torch.cuda.amp.autocast():\n            outputs = model(imgs)\n        _, preds = torch.max(outputs, 1)\n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n\nacc = accuracy_score(all_labels, all_preds)\nf1 = f1_score(all_labels, all_preds, average=\"weighted\")\nprecision = precision_score(all_labels, all_preds, average=\"weighted\")\nrecall = recall_score(all_labels, all_preds, average=\"weighted\")\ncm = confusion_matrix(all_labels, all_preds)\n\nprint(f\"\\nðŸ“Š Accuracy: {acc:.4f}\")\nprint(f\"ðŸ“Š F1 Score: {f1:.4f}\")\nprint(f\"ðŸ“Š Precision: {precision:.4f}\")\nprint(f\"ðŸ“Š Recall: {recall:.4f}\")\nprint(\"\\nClassification Report:\\n\", classification_report(all_labels, all_preds))\n\nplt.figure(figsize=(8,6))\nsns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n            xticklabels=[0,1,2,3,4], yticklabels=[0,1,2,3,4])\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\nplt.title(\"ResNet101 Confusion Matrix\")\nplt.tight_layout()\nplt.show()\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}