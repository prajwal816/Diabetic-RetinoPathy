{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14774,"databundleVersionId":875431,"sourceType":"competition"}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nimport timm\nfrom tqdm import tqdm   # âœ… progress bar\nimport random\n\n# ----------------------------\n# Config\n# ----------------------------\nIMG_SIZE = 224\nBATCH_SIZE = 16\nEPOCHS = 20\nLR = 1e-4\nSEED = 42\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\ntorch.manual_seed(SEED)\n\n# ----------------------------\n# Dataset\n# ----------------------------\nclass APTOSDataset(Dataset):\n    def __init__(self, df, img_dir, transform=None):\n        self.df = df\n        self.img_dir = img_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img_path = os.path.join(self.img_dir, row['id_code'] + \".png\")\n        image = Image.open(img_path).convert(\"RGB\")\n        label = row['diagnosis']\n        if self.transform:\n            image = self.transform(image)\n        return image, label\n\n# ----------------------------\n# Data Preparation\n# ----------------------------\ndf = pd.read_csv(\"/kaggle/input/aptos2019-blindness-detection/train.csv\")\n\ntrain_df, val_df = train_test_split(\n    df, test_size=0.2, stratify=df[\"diagnosis\"], random_state=SEED\n)\n\ntrain_transform = transforms.Compose([\n    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n    transforms.RandomRotation(15),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],\n                         [0.229, 0.224, 0.225]),\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],\n                         [0.229, 0.224, 0.225]),\n])\n\ntrain_dataset = APTOSDataset(train_df, \"/kaggle/input/aptos2019-blindness-detection/train_images\", transform=train_transform)\nval_dataset = APTOSDataset(val_df, \"/kaggle/input/aptos2019-blindness-detection/train_images\", transform=val_transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n\n# ----------------------------\n# Model: Swin Transformer\n# ----------------------------\nmodel = timm.create_model(\"swin_base_patch4_window7_224\", pretrained=True, num_classes=5)\nmodel = model.to(DEVICE)\n\n# Loss with label smoothing\ncriterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n\n# Optimizer + Scheduler\noptimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\nscheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n\n# ----------------------------\n# Training Loop with tqdm\n# ----------------------------\nbest_acc = 0.0\n\nfor epoch in range(EPOCHS):\n    # ---- Train ----\n    model.train()\n    train_loss, train_preds, train_targets = 0, [], []\n    \n    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Train]\", leave=False)\n    for imgs, labels in train_bar:\n        imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n        \n        optimizer.zero_grad()\n        outputs = model(imgs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n        preds = outputs.argmax(1).detach().cpu().numpy()\n        train_preds.extend(preds)\n        train_targets.extend(labels.cpu().numpy())\n\n        train_bar.set_postfix(loss=loss.item())\n\n    train_acc = accuracy_score(train_targets, train_preds)\n\n    # ---- Validation ----\n    model.eval()\n    val_loss, val_preds, val_targets = 0, [], []\n    val_bar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Val]\", leave=False)\n    with torch.no_grad():\n        for imgs, labels in val_bar:\n            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n            outputs = model(imgs)\n            loss = criterion(outputs, labels)\n\n            val_loss += loss.item()\n            preds = outputs.argmax(1).detach().cpu().numpy()\n            val_preds.extend(preds)\n            val_targets.extend(labels.cpu().numpy())\n\n            val_bar.set_postfix(loss=loss.item())\n\n    val_acc = accuracy_score(val_targets, val_preds)\n\n    print(f\"Epoch {epoch+1}/{EPOCHS} | \"\n          f\"Train Loss: {train_loss/len(train_loader):.4f}, \"\n          f\"Train Acc: {train_acc:.4f} | \"\n          f\"Val Loss: {val_loss/len(val_loader):.4f}, \"\n          f\"Val Acc: {val_acc:.4f}\")\n    \n    scheduler.step()\n\n    # Save best model\n    if val_acc > best_acc:\n        best_acc = val_acc\n        torch.save(model.state_dict(), \"best_swin.pth\")\n        best_preds, best_targets = val_preds.copy(), val_targets.copy()\n\nprint(\"Training complete. Best Val Acc:\", best_acc)\n\n# ----------------------------\n# Evaluation Report\n# ----------------------------\nprint(\"\\nClassification Report:\")\nprint(classification_report(best_targets, best_preds, target_names=[f\"Class {i}\" for i in range(5)]))\n\n# Confusion Matrix\ncm = confusion_matrix(best_targets, best_preds)\nplt.figure(figsize=(6,5))\nsns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n            xticklabels=[f\"Class {i}\" for i in range(5)],\n            yticklabels=[f\"Class {i}\" for i in range(5)])\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\nplt.title(\"Confusion Matrix\")\nplt.show()\n\n# ----------------------------\n# Single Image Prediction\n# ----------------------------\nmodel.load_state_dict(torch.load(\"best_swin.pth\", map_location=DEVICE))\nmodel.eval()\n\n# pick random sample from validation set\nidx = random.randint(0, len(val_df)-1)\nsample = val_df.iloc[idx]\nimg_path = os.path.join(\"/kaggle/input/aptos2019-blindness-detection/train_images\", sample['id_code']+\".png\")\n\nimage = Image.open(img_path).convert(\"RGB\")\ninput_tensor = val_transform(image).unsqueeze(0).to(DEVICE)\n\nwith torch.no_grad():\n    output = model(input_tensor)\n    pred_class = output.argmax(1).item()\n\nplt.imshow(image)\nplt.axis(\"off\")\nplt.title(f\"True: {sample['diagnosis']} | Pred: {pred_class}\")\nplt.show()\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}